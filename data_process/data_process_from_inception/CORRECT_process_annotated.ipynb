{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59cfd6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import spacy\n",
    "nlp = spacy.load(\"nl_core_news_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2723fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_parser(tsv):\n",
    "    \"\"\"\n",
    "    Function from Jenia to add metadata (will improve this description)\n",
    "    \"\"\"\n",
    "    # I am also adding the file number as metadata as I loaded in several notes per file\n",
    "    file_nr = tsv.split('_')[-1]\n",
    "    file_nr = file_nr.replace(\".conll/edwin.tsv\", \"\")\n",
    "\n",
    "    return dict(\n",
    "        file_nr = file_nr,\n",
    "        year = \"2020\", # tot 2021, 2022\n",
    "        annotator = \"edwin\",\n",
    "        batch = \"ergotherapie\",\n",
    "    )\n",
    "\n",
    "def tsv_to_df(filepath):\n",
    "    \"\"\"\n",
    "    Jenia's function that reads the tsv file as a dataframe and adds metadata\n",
    "    (will improve this description)\n",
    "    \"\"\"\n",
    "    metadata = legacy_parser(filepath)\n",
    "    \n",
    "    # in my case, the first column isn't the sent_index but the note index + token within note index\n",
    "    names = ['note_tok_index', 'char', 'token', 'label', 'relation']\n",
    "    return pd.read_csv(\n",
    "        filepath,\n",
    "        sep='\\t',\n",
    "        skiprows=5,\n",
    "        quoting=3,\n",
    "        names=names\n",
    "    ).dropna(how='all').query(\"note_tok_index.str[0] != '#'\").assign(\n",
    "        **metadata\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4503a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "annotated_list = []\n",
    "\n",
    "for file in glob.glob(\"./../../../inception_output/ergotherapie_output/annotation/ergotherapie_notities_*[0-9].conll/edwin.tsv\"):\n",
    "    annotated_list.append(tsv_to_df(file))\n",
    "\n",
    "annotated = pd.concat(annotated_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac5bd7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the note index from the first column\n",
    "annotated[\"NotitieID\"] = annotated[\"note_tok_index\"].apply(lambda x:x.split(\"-\")[0])\n",
    "# add an extra 0 to single digits (e.g. 1 becomes 01) so the order is preserved\n",
    "annotated[\"NotitieID\"] = annotated[\"NotitieID\"].apply(lambda x: str(\"0\" + x) if len(x)==1 else x)\n",
    "# also add the file number to the note ID so none of the IDs are the same\n",
    "annotated[\"NotitieID\"] = annotated[\"NotitieID\"] + annotated[\"file_nr\"] + \"003\"\n",
    "\n",
    "# 001 voor fysiotherapie\n",
    "# 002 voor dietetiek\n",
    "# 003 voor ergotherapie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42ebe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of the order of the indices\n",
    "annotated[\"order\"] = annotated.index.values\n",
    "# sort according to note IDs while preserving order within notes\n",
    "annotated = annotated.sort_values(by=[\"NotitieID\",\"order\"]).reset_index()\n",
    "annotated = annotated.drop(columns=[\"order\"])\n",
    "\n",
    "# create a temporary dataframe thats join the individual words together into notes again,\n",
    "# so spaCy can determine sentence boundaries\n",
    "annotated_notes = annotated.groupby([\"NotitieID\"])[\"token\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "annotated_notes.rename(columns={'token': 'note'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b0174be",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "\n",
    "# load notes into spacy and determine sentence boundaries,\n",
    "# store all indices into list\n",
    "for note in annotated_notes.iterrows():\n",
    "    sen_index = 0\n",
    "    tok_index = 0\n",
    "    doc = nlp(str(note[1][1]))\n",
    "    for token in doc:\n",
    "        # add tuples of sentence index, note index and token index to list\n",
    "        index_list.append({\"sen_idx\":sen_index,\"note_idx\":note[1][0],\"tok_idx\":tok_index})\n",
    "        # in her original code, Jenia used 'token.is_sent_start' to check sentence boundaries\n",
    "        if token.is_sent_start == True:\n",
    "            sen_index += 1\n",
    "        tok_index += 1\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e054ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the sentence and token index to the original dataframe\n",
    "df_tmp = pd.DataFrame(index_list)\n",
    "annotated[\"sen_id\"] = df_tmp[\"sen_idx\"]\n",
    "annotated[\"tok_id\"] = df_tmp[\"tok_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ea28c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated.to_pickle(\"./../../INCEPTION/ergotherapie.pkl\")\n",
    "annotated.to_csv(\"./../../INCEPTION/ergotherapie.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ca9db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
